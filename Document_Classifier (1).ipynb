{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Task 1: Data Exploration and Preprocessing**\n",
        "\n",
        "**Step 1.1: Load the Dataset**"
      ],
      "metadata": {
        "id": "W8j5qtaD77V-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data = pd.read_csv(\"/content/Document_Classifier_Dataset(Document_Classifier_Dataset).csv\")\n",
        "\n",
        "# Display the first few rows to understand the structure\n",
        "print(data.head())\n",
        "print(data.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_p8kVQb8Bpfy",
        "outputId": "8764ba10-2564-4c64-f156-cdc46151025e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ID                                               Text    Category\n",
            "0   1  Abstract: Wish up music want go prove happy. V...  Scientific\n",
            "1   2  This agreement is made between Grimes, Kaufman...       Legal\n",
            "2   3  I recently purchased land and it exceeded my e...  E-commerce\n",
            "3   4  This agreement is made between Brown PLC and V...       Legal\n",
            "4   5  I recently purchased wrong and it was disappoi...  E-commerce\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3000 entries, 0 to 2999\n",
            "Data columns (total 3 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   ID        3000 non-null   int64 \n",
            " 1   Text      3000 non-null   object\n",
            " 2   Category  3000 non-null   object\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 70.4+ KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1.2: Understand the Dataset**\n",
        "From the information given:\n",
        "\n",
        "The dataset contains three columns: ID, Text, and Category.\n",
        "\n",
        "Text is the feature column containing the document content.\n",
        "\n",
        "Category is the label column with predefined categories (e.g., News Articles, Scientific Papers, Legal Documents, etc.).\n",
        "\n",
        "**Step 1.3: Text Preprocessing**\n",
        "\n",
        "Tokenization: Splitting text into individual words.\n",
        "\n",
        "Stop-word Removal: Removing common words like “the,” “is,” etc.\n",
        "\n",
        "Lemmatization: Reducing words to their base forms (e.g., “running” → “run”).\n",
        "\n",
        "Vectorization: Converting text into numerical format using TF-IDF."
      ],
      "metadata": {
        "id": "J79-vJJoCMmP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download necessary NLTK resources\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Initialize preprocessing tools\n",
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Preprocessing function\n",
        "def preprocess_text(text):\n",
        "    # Remove non-alphabetic characters and convert text to lowercase\n",
        "    text = re.sub(r'\\W', ' ', text.lower())\n",
        "    # Remove extra spaces\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    # Tokenize, remove stop words, and lemmatize\n",
        "    text = ' '.join([lemmatizer.lemmatize(word) for word in text.split() if word not in stop_words])\n",
        "    return text\n",
        "\n",
        "# Apply preprocessing to the Text column\n",
        "data['Processed_Text'] = data['Text'].apply(preprocess_text)\n",
        "\n",
        "# Display a sample of the preprocessed text\n",
        "print(\"Sample Preprocessed Text:\", data['Processed_Text'].iloc[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNHeLta5OTHd",
        "outputId": "bebb82e4-2fcd-4f8d-c641-c0cb80e2f737"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Preprocessed Text: abstract wish music want go prove happy various information begin wear decision speech attention plan building mission building collection speak difference worry approach source rock business side green structure section wish network remember material none particularly keywords thus join fish scene national\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1.4: Vectorization**\n",
        "\n",
        "Use TF-IDF to convert text into numerical features."
      ],
      "metadata": {
        "id": "54CDNbMJOXhO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorize the preprocessed text using TF-IDF\n",
        "vectorizer = TfidfVectorizer(max_features=5000)  # Limit to top 5000 features\n",
        "X = vectorizer.fit_transform(data['Processed_Text']).toarray()\n",
        "\n",
        "# Encode the labels\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "encoder = LabelEncoder()\n",
        "y = encoder.fit_transform(data['Category'])\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Training data shape:\", X_train.shape)\n",
        "print(\"Testing data shape:\", X_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfuNPgpPOZqi",
        "outputId": "162a8ce2-6a80-4895-a2f3-8982c524c97c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape: (2400, 1685)\n",
            "Testing data shape: (600, 1685)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Task 2: Model Development**\n",
        "\n",
        "**Step 2.1: Train Logistic Regression**"
      ],
      "metadata": {
        "id": "7SWfMIxLOfPq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Train Logistic Regression model\n",
        "lr_model = LogisticRegression(max_iter=100)\n",
        "lr_model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate Logistic Regression\n",
        "y_pred_lr = lr_model.predict(X_test)\n",
        "print(\"Logistic Regression Evaluation:\\n\", classification_report(y_test, y_pred_lr))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oAo9uisROno8",
        "outputId": "be75778f-5c01-496c-ff59-141196f10f3e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Evaluation:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       118\n",
            "           1       1.00      1.00      1.00       119\n",
            "           2       1.00      1.00      1.00       131\n",
            "           3       1.00      0.98      0.99       131\n",
            "           4       1.00      1.00      1.00       101\n",
            "\n",
            "    accuracy                           0.99       600\n",
            "   macro avg       1.00      1.00      1.00       600\n",
            "weighted avg       1.00      0.99      1.00       600\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2.2: Train LSTM Model**\n"
      ],
      "metadata": {
        "id": "AO2_2oIBOryn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "import numpy as np\n",
        "\n",
        "# Parameters for LSTM\n",
        "vocab_size = 5000  # Number of unique tokens in the vocabulary\n",
        "embed_dim = 128    # Embedding dimension size\n",
        "max_length = X.shape[1]  # Number of timesteps (matches the number of features from TF-IDF)\n",
        "\n",
        "# Convert data to the correct shape (batch_size, timesteps)\n",
        "X_train_lstm = X_train  # Already in 2D from TF-IDF\n",
        "X_test_lstm = X_test    # Already in 2D from TF-IDF\n",
        "\n",
        "# Build LSTM model\n",
        "lstm_model = Sequential([\n",
        "    Embedding(input_dim=vocab_size, output_dim=embed_dim, input_length=max_length),\n",
        "    LSTM(128, dropout=0.2, recurrent_dropout=0.2),  # LSTM layer with 128 units\n",
        "    Dropout(0.5),\n",
        "    Dense(len(encoder.classes_), activation='softmax')  # Output layer for classification\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "lstm_model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(lstm_model.summary())\n",
        "\n",
        "# Train LSTM\n",
        "lstm_model.fit(X_train_lstm, y_train, epochs=5, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Evaluate LSTM\n",
        "y_pred_lstm = lstm_model.predict(X_test_lstm).argmax(axis=1)\n",
        "print(\"LSTM Evaluation:\\n\", classification_report(y_test, y_pred_lstm))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 815
        },
        "id": "-2fD--XyOt7p",
        "outputId": "ac8f770b-e071-4e84-e8f9-50493c36eef4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)              │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "Epoch 1/5\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m250s\u001b[0m 4s/step - accuracy: 0.2133 - loss: 1.6147 - val_accuracy: 0.1958 - val_loss: 1.6133\n",
            "Epoch 2/5\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m253s\u001b[0m 4s/step - accuracy: 0.1896 - loss: 1.6116 - val_accuracy: 0.2375 - val_loss: 1.6118\n",
            "Epoch 3/5\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m267s\u001b[0m 4s/step - accuracy: 0.2113 - loss: 1.6097 - val_accuracy: 0.1958 - val_loss: 1.6161\n",
            "Epoch 4/5\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 4s/step - accuracy: 0.2113 - loss: 1.6062 - val_accuracy: 0.2375 - val_loss: 1.6081\n",
            "Epoch 5/5\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 5s/step - accuracy: 0.1973 - loss: 1.6107 - val_accuracy: 0.1958 - val_loss: 1.6107\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 958ms/step\n",
            "LSTM Evaluation:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       118\n",
            "           1       0.00      0.00      0.00       119\n",
            "           2       0.22      1.00      0.36       131\n",
            "           3       0.00      0.00      0.00       131\n",
            "           4       0.00      0.00      0.00       101\n",
            "\n",
            "    accuracy                           0.22       600\n",
            "   macro avg       0.04      0.20      0.07       600\n",
            "weighted avg       0.05      0.22      0.08       600\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Task 3: Evaluation**\n",
        "\n",
        "To evaluate both the Logistic Regression and LSTM models, you need to use metrics such as accuracy, precision, recall, and F1-score. These metrics help in understanding the performance of each model on the test dataset.\n",
        "\n"
      ],
      "metadata": {
        "id": "a8-wSXU8UGUr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3.1: Import Required Libraries**"
      ],
      "metadata": {
        "id": "r68vHPzIUMLN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report"
      ],
      "metadata": {
        "id": "FUqKhpnqUJ0M"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**`Step 3.2: Evaluate Logistic Regression`**"
      ],
      "metadata": {
        "id": "eAzbaqt6UTPm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions for Logistic Regression\n",
        "y_pred_lr = lr_model.predict(X_test)\n",
        "\n",
        "# Calculate metrics for Logistic Regression\n",
        "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
        "precision_lr = precision_score(y_test, y_pred_lr, average='weighted')\n",
        "recall_lr = recall_score(y_test, y_pred_lr, average='weighted')\n",
        "f1_lr = f1_score(y_test, y_pred_lr, average='weighted')\n",
        "\n",
        "print(\"Logistic Regression Evaluation:\")\n",
        "print(f\"Accuracy: {accuracy_lr}\")\n",
        "print(f\"Precision: {precision_lr}\")\n",
        "print(f\"Recall: {recall_lr}\")\n",
        "print(f\"F1-Score: {f1_lr}\")\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_lr))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRZHnn-PUVSC",
        "outputId": "5d5f407d-e0c8-48b8-9156-6678829ec527"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Evaluation:\n",
            "Accuracy: 0.995\n",
            "Precision: 0.9951239669421489\n",
            "Recall: 0.995\n",
            "F1-Score: 0.9950024232241806\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       118\n",
            "           1       1.00      1.00      1.00       119\n",
            "           2       1.00      1.00      1.00       131\n",
            "           3       1.00      0.98      0.99       131\n",
            "           4       1.00      1.00      1.00       101\n",
            "\n",
            "    accuracy                           0.99       600\n",
            "   macro avg       1.00      1.00      1.00       600\n",
            "weighted avg       1.00      0.99      1.00       600\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3.3: Evaluate LSTM**"
      ],
      "metadata": {
        "id": "iFob__NoUZjd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions for LSTM\n",
        "y_pred_lstm = lstm_model.predict(X_test_lstm).argmax(axis=1)\n",
        "\n",
        "# Calculate metrics for LSTM\n",
        "accuracy_lstm = accuracy_score(y_test, y_pred_lstm)\n",
        "precision_lstm = precision_score(y_test, y_pred_lstm, average='weighted')\n",
        "recall_lstm = recall_score(y_test, y_pred_lstm, average='weighted')\n",
        "f1_lstm = f1_score(y_test, y_pred_lstm, average='weighted')\n",
        "\n",
        "print(\"LSTM Evaluation:\")\n",
        "print(f\"Accuracy: {accuracy_lstm}\")\n",
        "print(f\"Precision: {precision_lstm}\")\n",
        "print(f\"Recall: {recall_lstm}\")\n",
        "print(f\"F1-Score: {f1_lstm}\")\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_lstm))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l87Mg9vMUa8Y",
        "outputId": "88403abe-d1bf-4f33-a390-8c67e9009ec0"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step\n",
            "LSTM Evaluation:\n",
            "Accuracy: 0.21833333333333332\n",
            "Precision: 0.047669444444444445\n",
            "Recall: 0.21833333333333332\n",
            "F1-Score: 0.07825353397172824\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       118\n",
            "           1       0.00      0.00      0.00       119\n",
            "           2       0.22      1.00      0.36       131\n",
            "           3       0.00      0.00      0.00       131\n",
            "           4       0.00      0.00      0.00       101\n",
            "\n",
            "    accuracy                           0.22       600\n",
            "   macro avg       0.04      0.20      0.07       600\n",
            "weighted avg       0.05      0.22      0.08       600\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3.4: Compare Results**\n",
        "\n",
        "Create a comparison table to summarize the performance of both models."
      ],
      "metadata": {
        "id": "VkWTToRtUdhB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print comparison\n",
        "print(\"Comparison of Models:\")\n",
        "print(f\"{'Metric':<15}{'Logistic Regression':<20}{'LSTM':<20}\")\n",
        "print(f\"{'Accuracy':<15}{accuracy_lr:<20.2f}{accuracy_lstm:<20.2f}\")\n",
        "print(f\"{'Precision':<15}{precision_lr:<20.2f}{precision_lstm:<20.2f}\")\n",
        "print(f\"{'Recall':<15}{recall_lr:<20.2f}{recall_lstm:<20.2f}\")\n",
        "print(f\"{'F1-Score':<15}{f1_lr:<20.2f}{f1_lstm:<20.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ckwMJ1OUiiH",
        "outputId": "f8f87913-e831-4f02-d4f5-d1b6c5301178"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comparison of Models:\n",
            "Metric         Logistic Regression LSTM                \n",
            "Accuracy       0.99                0.22                \n",
            "Precision      1.00                0.05                \n",
            "Recall         0.99                0.22                \n",
            "F1-Score       1.00                0.08                \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Task 4: Optimization**\n",
        "\n",
        "**Step 4.1: Optimize Logistic Regression (Grid Search)**\n",
        "\n",
        "Grid Search systematically tests combinations of hyperparameters to find the best-performing configuration. For Logistic Regression, we can optimize:\n",
        "\n",
        "C: Regularization strength.\n",
        "\n",
        "solver: Optimization algorithm."
      ],
      "metadata": {
        "id": "PsD7Q6v0VOeG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the hyperparameter grid\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10, 100],  # Regularization strength\n",
        "    'solver': ['liblinear', 'lbfgs']  # Optimization solvers\n",
        "}\n",
        "\n",
        "# Create the GridSearchCV object\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=LogisticRegression(max_iter=200),\n",
        "    param_grid=param_grid,\n",
        "    scoring='f1_weighted',  # Optimizing for F1-score\n",
        "    cv=3  # 3-fold cross-validation\n",
        ")\n",
        "\n",
        "# Perform the search\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best hyperparameters and corresponding score\n",
        "print(\"Best Hyperparameters for Logistic Regression:\", grid_search.best_params_)\n",
        "print(\"Best F1-Score:\", grid_search.best_score_)\n",
        "\n",
        "# Use the best model for predictions\n",
        "best_lr_model = grid_search.best_estimator_\n",
        "y_pred_lr_optimized = best_lr_model.predict(X_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0HoGAu12VTpL",
        "outputId": "cfdf0fbd-daf8-46ac-a3dd-ca280bdbe57f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters for Logistic Regression: {'C': 100, 'solver': 'liblinear'}\n",
            "Best F1-Score: 0.9983338389889505\n"
          ]
        }
      ]
    }
  ]
}